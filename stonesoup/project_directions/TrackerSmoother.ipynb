{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84efc24d-f7ab-46e7-8b9a-94e1860b4c76",
   "metadata": {},
   "source": [
    "# Tracker improvement for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4dc4c-0325-426f-a85a-ceb5bc0c6c15",
   "metadata": {},
   "source": [
    "Consider the scenario where the target evolves according to the Langevin model, driven by a normal sigma-mean mixture with the mixing distribution being the $\\alpha$-stable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3a32a-bd28-4847-9bc9-46c810cef76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the local stonesoup directory to sys.path\n",
    "project_path = r\"C:\\Users\\joesb\\Documents\\stonesoup\"  # Adjust this to your actual path\n",
    "if project_path not in sys.path:\n",
    "    sys.path.insert(0, project_path)\n",
    "\n",
    "# print(sys.path)\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a277e3e-e853-4f90-b431-a5a13b380f48",
   "metadata": {},
   "source": [
    "The state of the target can be represented as 2D Cartesian coordinates, $\\left[x, \\dot x, y, \\dot y\\right]^{\\top}$, modelling both its position and velocity. A simple truth path is created with a sampling rate of 1 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3940b-6e0c-4c2f-bd8a-4844802e0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.models.base_driver import GaussianResidualApproxCase\n",
    "from stonesoup.models.driver import AlphaStableNSMDriver \n",
    "from stonesoup.models.transition.levylinear import LevyLangevin, CombinedLinearLevyTransitionModel\n",
    "\n",
    "# And the clock starts\n",
    "start_time = datetime.now().replace(microsecond=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69026f8d-bb9e-4673-b177-45d12cbed859",
   "metadata": {},
   "source": [
    "The `LevyLangevin` class creates a one-dimensional Langevin model, driven by the $\\alpha$-stable NSM mixture process defined in the `AlphaStableNSMDriver` class.\n",
    "\n",
    "\\begin{equation}\n",
    "d \\dot{x}(t)=-\\theta \\dot{x}(t) d t+d W(t), \\quad \\theta>0\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta$ is the damping factor and $W(t)$ is the non-Gaussian driving process.\n",
    "\n",
    "The noise samples $\\mathbf{w}_n$ are drawn from the $\\alpha$-stable distribution parameterized by the $\\alpha$-stable law, $S_{\\alpha}(\\sigma, \\beta, \\mu)$.\n",
    "\n",
    "The input parameters to `AlphaStableNSMDriver` class are the stability index $\\alpha$, expected jumps per unit time $c$, conditional Gaussian mean $\\mu_W$ & variance $\\sigma_W^2$, and the type of residuals used for the truncated shot-noise representation, specified by `noise_case`. \n",
    "\n",
    "Without diving into technical details, the scaling factor $\\sigma$, skewness parameter $\\beta$ and location $\\mu$, in the $\\alpha$-stable law is a function of the conditional Gaussian parameters $\\mu_W, \\sigma_W^2$. In general, set $\\mu_W=0$ for a symmetric target distribution $\\beta=0$, or $\\mu_W \\neq 0$ to model biased trajectories otherwise. In addition, the size of the resulting trajectories (and jumps) can be adjusted by varying $\\sigma_W^2$.\n",
    "\n",
    "The available noise cases are:\n",
    "\n",
    "1. No residuals, `TruncatedCase`, least expensive but drawn noise samples deviate further from target distribution.\n",
    "2. `GaussianResidualApproxCase`, the most expensive but drawn noise samples closest target distribution.\n",
    "3. `PartialGaussianResidualApproxCase`, a compromise between both cases (1) and (2).\n",
    "\n",
    "\n",
    "For interested readers, refer to [1, 2] for more details.\n",
    "\n",
    "Here, we initialise an $\\alpha$-stable driver with the default parameters `mu_W=0, sigma_W2=1, alpha=1.4, noise_case=GaussianResidualApproxCase(), c=10`.\n",
    "\n",
    "Then, the driver instance is injected into the Langevin model for every coordinate axes (i.e., x and y) during initialisation with parameter `damping_coeff=0.15`.\n",
    "\n",
    "Note that we overwrite the default `mu_W` parameter in the $\\alpha$-stable driver for the x-coordinate axes to bias our trajectories towards the left. This can be done by passing an additional argument `mu_W = -0.02` when injecting the driver into the Langevin model.\n",
    "\n",
    "Finallt, the `CombinedLinearLevyTransitionModel` class takes a set of 1-D models and combines them into a linear transition model of arbitrary dimension, $D$, (in this case, $D=2$).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- and  in the $\\alpha$-stable law is a function of the conditional Gaussian mean $\\mu_W$\n",
    "\n",
    "where $\\beta=\\begin{cases} 1, \\quad \\mu_W \\neq 0 \\\\ 0, \\quad \\text{otherwise} \\end{cases}$ with $\\beta=0$ being the a symmetric stable distribution.\n",
    "\n",
    "$\\sigma=\\frac{\\mathbb{E}|w|^\\alpha \\Gamma(2-\\alpha) \\cos(\\pi \\alpha / 2))}{1- \\alpha}$ represent the scale parameter and $\\beta=$ controlling the skewness of the stable distribution. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fd30c-e869-47e6-9cb5-8907df8b1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1 # Random seem for reproducibility\n",
    "\n",
    "# Driving process parameters\n",
    "mu_W = 0\n",
    "sigma_W2 = 4\n",
    "alpha = 1.4\n",
    "c=10\n",
    "noise_case=GaussianResidualApproxCase()\n",
    "\n",
    "# Model parameters\n",
    "theta=0.15\n",
    "\n",
    "driver_x = AlphaStableNSMDriver(mu_W=mu_W, sigma_W2=sigma_W2, seed=seed, c=c, alpha=alpha, noise_case=noise_case)\n",
    "driver_y = driver_x # Same driving process in both dimensions and sharing the same latents (jumps)\n",
    "langevin_x = LevyLangevin(driver=driver_x, damping_coeff=theta, mu_W=-0.02)\n",
    "langevin_y = LevyLangevin(driver=driver_y, damping_coeff=theta)\n",
    "transition_model = CombinedLinearLevyTransitionModel([langevin_x, langevin_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2f4db-995e-42df-995c-0b62be09fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transition_model.mu_W)\n",
    "print(transition_model.sigma_W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c85f9-34d1-4d81-bf23-2838f55d0fcf",
   "metadata": {},
   "source": [
    "The ground truth is initialised from (0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381158e-3147-4b6d-a982-4aa959f4c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [start_time]\n",
    "truth = GroundTruthPath([GroundTruthState([0, 1, 0, 1], timestamp=timesteps[0])])\n",
    "\n",
    "num_steps = 50\n",
    "for k in range(1, num_steps + 1):\n",
    "    timesteps.append(start_time+timedelta(seconds=1*k))  # add next timestep to list of timesteps\n",
    "    truth.append(GroundTruthState(\n",
    "        transition_model.function(truth[k-1], noise=True, time_interval=timedelta(seconds=1)),\n",
    "        timestamp=timesteps[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6d666-f45d-4344-a2d9-865f599e256b",
   "metadata": {},
   "source": [
    "The simulated ground truth path can be plotted using the in-built plotting classes in Stone Soup.\n",
    "\n",
    "In addition to the ground truth, Stone Soup plotting tools allow measurements and predicted tracks (see later) to be plotted and synced together consistently.\n",
    "\n",
    "An animated plotter that uses Plotly graph objects can be accessed via the `AnimatedPlotterly` class from Stone Soup.\n",
    "\n",
    "Note that the animated plotter requires a list of timesteps as an input, and that `tail_length`\n",
    "is set to 0.3. This means that each data point will be on display for 30% of the total\n",
    "simulation time. The mapping argument is [0, 2] because those are the x and\n",
    "y position indices from our state vector.\n",
    "\n",
    "If a static plotter is preferred, the `Plotterly` class can be used instead\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1143d2f-aeaa-44e8-8b01-479a80e0601b",
   "metadata": {},
   "source": [
    "## Simulate measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea94e4b-23fc-465d-ad63-d3417eb708a6",
   "metadata": {},
   "source": [
    "Assume a 'linear' sensor which detects the\n",
    "position, but not velocity, of a target, such that\n",
    "$\\mathbf{z}_k = H_k \\mathbf{x}_k + \\boldsymbol{\\nu}_k$,\n",
    "$\\boldsymbol{\\nu}_k \\sim \\mathcal{N}(0,R)$, with\n",
    "\n",
    "\\begin{align}H_k &= \\begin{bmatrix}\n",
    "                    1 & 0 & 0 & 0\\\\\n",
    "                    0  & 0 & 1 & 0\\\\\n",
    "                      \\end{bmatrix}\\\\\n",
    "          R &= \\begin{bmatrix}\n",
    "                  25 & 0\\\\\n",
    "                    0 & 25\\\\\n",
    "               \\end{bmatrix}\n",
    "\\omega\\end{align}\n",
    "\n",
    "where $\\omega$ is set to 25 initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f6231-6728-4ff7-b388-581c4284d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.models.measurement.linear import LinearGaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0ec57-951a-4ba7-b0fb-a0409f21cb1b",
   "metadata": {},
   "source": [
    "The linear Gaussian measurement model is set up by indicating the number of dimensions in the\n",
    "state vector and the dimensions that are measured (so specifying $H_k$) and the noise\n",
    "covariance matrix $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe185d-00bc-4fbc-950c-824ba9bdc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,  # Number of state dimensions (position and velocity in 2D)\n",
    "    mapping=(0, 2),  # Mapping measurement vector index to state index\n",
    "    noise_covar=np.array([[15, 0],  # Covariance matrix for Gaussian PDF\n",
    "                          [0, 15]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d2d6b-a6b6-4d9a-8525-764bdfa855cd",
   "metadata": {},
   "source": [
    "The measurements can now be generated and plotted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0346af-dd50-4e2f-b736-1c33baf95326",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = []\n",
    "for state in truth:\n",
    "    measurement = measurement_model.function(state, noise=True)\n",
    "    measurements.append(Detection(measurement,\n",
    "                                  timestamp=state.timestamp,\n",
    "                                  measurement_model=measurement_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b6cae-87a4-4050-a09c-6f511f9b37b8",
   "metadata": {},
   "source": [
    "## Marginalised Particle Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebcae6-4bdf-42fa-8806-443e2b18e576",
   "metadata": {},
   "source": [
    "The `MarginalisedParticlePredictor` and `MarginalisedParticleUpdater` classes correspond to the predict and update steps\n",
    "respectively.\n",
    "Both require a `TransitionModel` and a `MeasurementModel` instance respectively.\n",
    "To avoid degenerate samples, the `SystematicResampler` is used which is passed to the updater.\n",
    "More resamplers that are included in Stone Soup are covered in the\n",
    "[Resampler Tutorial](https://stonesoup.readthedocs.io/en/latest/auto_tutorials/sampling/ResamplingTutorial.html#sphx-glr-auto-tutorials-sampling-resamplingtutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4284e1f-20e5-4d1f-a5da-06cf0c93a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.predictor.particle import MarginalisedParticlePredictor\n",
    "from stonesoup.resampler.particle import SystematicResampler, SystematicResampler_with_parents\n",
    "from stonesoup.updater.particle import MarginalisedParticleUpdater\n",
    "\n",
    "predictor = MarginalisedParticlePredictor(transition_model=transition_model)\n",
    "resampler = SystematicResampler(resample_index=True)\n",
    "updater = MarginalisedParticleUpdater(measurement_model, resampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb779115-7823-4bdb-aad1-74d0e076cbdf",
   "metadata": {},
   "source": [
    "To start we create a prior estimate. This is a `MarginalisedParticleState` which describes the state as a distribution of particles.\n",
    "\n",
    "The mean priors are randomly sampled from the standard normal distribution.\n",
    "\n",
    "The covariance priors is initialised with a scalar multiple of the identity matrix ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf7062-e0e3-4ab2-8592-31472ad0d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from stonesoup.types.numeric import Probability  # Similar to a float type\n",
    "from stonesoup.types.state import MarginalisedParticleState\n",
    "from stonesoup.types.array import StateVectors\n",
    "\n",
    "number_particles = 50\n",
    "\n",
    "# Sample from the prior Gaussian distribution\n",
    "states = multivariate_normal.rvs(np.array([0, 1, 0, 1]),\n",
    "                                  np.diag([1., 1., 1., 1.]),\n",
    "                                  size=number_particles)\n",
    "covars = np.stack([np.eye(4) * 100 for i in range(number_particles)], axis=2) # (M, M, N)\n",
    "\n",
    "# Create prior particle state.\n",
    "prior = MarginalisedParticleState(\n",
    "    state_vector=StateVectors(states.T),\n",
    "    covariance=covars,\n",
    "    weight=np.array([Probability(1/number_particles)]*number_particles),\n",
    "                      timestamp=start_time-timedelta(seconds=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fb70b-88a0-4a8d-a0e4-b7911a34be09",
   "metadata": {},
   "source": [
    "We now run the predict and update steps, propagating the collection of particles and resampling at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac5271-b7b3-44b8-9324-ef1b74d9f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.track import Track\n",
    "from stonesoup.plotter import AnimatedPlotterly, _Plotter, Plotterly, MetricPlotter, Dimension, AnimationPlotter\n",
    "\n",
    "track = Track()\n",
    "history=True\n",
    "\n",
    "for measurement in measurements:\n",
    "    prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "    hypothesis = SingleHypothesis(prediction, measurement)\n",
    "    post, history = updater.update(hypothesis, history=history)\n",
    "    track.append(post)\n",
    "    prior = track[-1]\n",
    "    print(f\"track length ={len(track)} of {len(measurements)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67db34f",
   "metadata": {},
   "source": [
    "# Implement Particle Smoother Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15318db3",
   "metadata": {},
   "source": [
    "### Descendant smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a9e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.smoother.particle import ParticleSmoother\n",
    "smoother=ParticleSmoother()\n",
    "particle_track_list=smoother.get_particle_paths(track=track, history=history)[0]\n",
    "\n",
    "descendant_smoothed_track=smoother.smooth(track, history, smooth_type='descendant', \n",
    "                                          lag_length=50, window_length=1, constant_lag=None, \n",
    "                                          keep_duplicates=None)\n",
    "\n",
    "print([len(track) for track in particle_track_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438857f",
   "metadata": {},
   "source": [
    "### Particle Smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2698be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_smoother(track, history, smooth_type='descendant',\n",
    "                      lag_length=50, window_length=1, constant_lag=None,\n",
    "                      keep_duplicates=None):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b19da6e",
   "metadata": {},
   "source": [
    "### Generate/plot particle track figures in 1D: ground truths/ measurements/ particle_tracks/ unsmoothed_track/ smoothed_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c403cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "axis_label_list=[\"x\",\"dx_dt\",\"y\",\"dy_dt\"]\n",
    "particle_plotter_dict = {}\n",
    "for i,label in enumerate(axis_label_list):\n",
    "    particle_plotter_dict[label]= Plotterly(autosize=True, dimension=Dimension.ONE, axis_labels=[label])\n",
    "    particle_plotter_dict[label].plot_ground_truths(truth, [i],mode=\"lines\", line=dict(width=1))\n",
    "    if label ==\"x\" or label==\"y\":\n",
    "        particle_plotter_dict[label].plot_measurements(measurements, [i],marker=dict(symbol=\"x\",size=4))\n",
    "    particle_plotter_dict[label].plot_tracks(track, [i],uncertainty=True,particle=True,mode=\"lines\", track_label=\"Original Track\",line=dict(width=1))\n",
    "    particle_plotter_dict[label].plot_tracks(particle_track_list, [i],mode=\"lines\",opacity=0.4,track_label=\"Particle Paths\",line=dict(width=0.5))\n",
    "    particle_plotter_dict[label].plot_tracks(descendant_smoothed_track, [i],mode=\"lines\",track_label=\"Smoothed Track\",line=dict(width=1))\n",
    "\n",
    "\n",
    "    file_path = Path(rf\"C:\\Users\\joesb\\OneDrive\\Documents\\Cambridge\\IIB\\PROJECT- Implementation of N-G TAs in SS framework\\Presentation_28th_Nov\\{num_steps}steps_{number_particles}p\\1D_plot_{label}.html\")\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    particle_plotter_dict[label].fig.write_html(str(file_path))\n",
    "    # particle_plotter_dict[label].fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a29ae37",
   "metadata": {},
   "source": [
    "### 2D Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4aa4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "animated=False\n",
    "animated_label_list= [\"xy_position\", \"xy_velocity\"]\n",
    "animated_mappings =[[0,2],[1,3]]\n",
    "animated_plotter_dict={}\n",
    "for i,label in enumerate(animated_label_list):\n",
    "    if label==\"xy_velocity\":\n",
    "        axis_labels=[\"dx/dt\",\"dy/dt\"]\n",
    "    else:\n",
    "        axis_labels=[\"x\",\"y\"]\n",
    "    if animated:\n",
    "        animated_plotter_dict[label]= AnimatedPlotterly(timesteps, tail_length=0.01, width=600, height=600,\n",
    "                                                    xaxis=dict(title=dict(text=f\"<i>{axis_labels[0]}</i>\")),\n",
    "                                                    yaxis=dict(title=dict(text=f\"<i>{axis_labels[1]}</i>\")))\n",
    "    else:\n",
    "        animated_plotter_dict[label]= Plotterly(autosize=True, axis_labels=axis_labels)\n",
    "    animated_plotter_dict[label].plot_ground_truths(truth, animated_mappings[i],line=dict(width=1))\n",
    "    if label== \"xy_position\":\n",
    "        animated_plotter_dict[label].plot_measurements(measurements, animated_mappings[i],marker=dict(symbol=\"x\",size=4))\n",
    "    animated_plotter_dict[label].plot_tracks(track, animated_mappings[i], particle=True, uncertainty=True, track_label=\"Track\",line=dict(width=1))\n",
    "    animated_plotter_dict[label].plot_tracks(particle_track_list, animated_mappings[i],mode=\"lines\",opacity=0.4,track_label=\"Particle Paths\",line=dict(width=0.5))\n",
    "    animated_plotter_dict[label].plot_tracks(descendant_smoothed_track, animated_mappings[i],track_label=\"Descendant Smoothed Track\",line=dict(width=1))\n",
    "    file_path = Path(rf\"C:\\Users\\joesb\\OneDrive\\Documents\\Cambridge\\IIB\\PROJECT- Implementation of N-G TAs in SS framework\\Presentation_28th_Nov\\{num_steps}steps_{number_particles}p\\2D_plot_{label}.html\")\n",
    "    file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    animated_plotter_dict[label].fig.write_html(str(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bc94f",
   "metadata": {},
   "source": [
    "## Testing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f535d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_filters = [\"unsmoothed\", \"descendant_smoothed\"]\n",
    "\n",
    "from stonesoup.metricgenerator.ospametric import OSPAMetric\n",
    "\n",
    "ospa_generators = [OSPAMetric(c=40, p=1,\n",
    "                              generator_name=f'{tracking_filter} OSPA metrics',\n",
    "                              tracks_key=f'tracks_{tracking_filter}',\n",
    "                              truths_key='truths'\n",
    "                             )\n",
    "                   for tracking_filter in tracking_filters]\n",
    "\n",
    "from stonesoup.metricgenerator.tracktotruthmetrics import SIAPMetrics\n",
    "from stonesoup.measures import Euclidean\n",
    "\n",
    "siap_generators = [SIAPMetrics(position_measure=Euclidean((0, 2)),\n",
    "                             velocity_measure=Euclidean((1, 3)),\n",
    "                             generator_name=f'{tracking_filter} SIAP metrics',\n",
    "                             tracks_key=f'tracks_{tracking_filter}',\n",
    "                             truths_key='truths'\n",
    "                            )\n",
    "                  for tracking_filter in tracking_filters]\n",
    "\n",
    "\n",
    "from stonesoup.metricgenerator.uncertaintymetric import SumofCovarianceNormsMetric\n",
    "\n",
    "uncertainty_generators = [\n",
    "    SumofCovarianceNormsMetric(generator_name=f'{tracking_filter} OSPA metrics',\n",
    "                               tracks_key=f'tracks_{tracking_filter}')\n",
    "    for tracking_filter in tracking_filters]\n",
    "\n",
    "from stonesoup.dataassociator.tracktotrack import TrackToTruth\n",
    "from stonesoup.metricgenerator.manager import MultiManager\n",
    "\n",
    "associator = TrackToTruth(association_threshold=30)\n",
    "\n",
    "generators = ospa_generators # + siap_generators + uncertainty_generators\n",
    "metric_manager = MultiManager(generators, associator=associator)\n",
    "\n",
    "metric_manager.add_data({'truths': [truth],\n",
    "                         'tracks_unsmoothed': [track],\n",
    "                         'tracks_descendant_smoothed': [descendant_smoothed_track]\n",
    "                         })\n",
    "metrics = metric_manager.generate_metrics()\n",
    "\n",
    "from stonesoup.plotter import MetricPlotter\n",
    "\n",
    "fig1 = MetricPlotter()\n",
    "fig1.plot_metrics(metrics, metric_names=['OSPA distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up distance error from ground truth over all timestamps\n",
    "for tracking_filter in tracking_filters:\n",
    "    total = sum([metrics[f'{tracking_filter} OSPA metrics']['OSPA distances'].value[i].value\n",
    "                 for i in range(0, len(metrics[f'{tracking_filter} OSPA metrics']['OSPA distances'].value))])\n",
    "    print(f'OSPA total value for {tracking_filter} is {total:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe40d82",
   "metadata": {},
   "source": [
    "# Kalman smoothing conditional on latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.smoother.kalman import ConditionallyGaussianLevySmoother\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c225b-b4fa-481a-9929-89b6168b454c",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Lemke, Tatjana, and Simon J. Godsill, 'Inference for models with asymmetric α -stable noise processes', in Siem Jan Koopman, and Neil Shephard (eds), Unobserved Components and Time Series Econometrics (Oxford, 2015; online edn, Oxford Academic, 21 Jan. 2016)\n",
    "\n",
    "[2] S. Godsill, M. Riabiz, and I. Kontoyiannis, “The L ́evy state space model,” in 2019 53rd Asilomar Conference on Signals, Systems, and Computers, 2019, pp. 487–494.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonesoup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
