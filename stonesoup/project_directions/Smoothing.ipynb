{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34e4177-f7d0-4841-967b-e759108109a2",
   "metadata": {},
   "source": [
    "## Lagged smoothing, t-L|0:t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e26462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the local stonesoup directory to sys.path\n",
    "project_path = r\"C:\\Users\\joesb\\Documents\\stonesoup\"  # Adjust this to your actual path\n",
    "if project_path not in sys.path:\n",
    "    sys.path.insert(0, project_path)\n",
    "\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ed441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.particle import Particle\n",
    "# Check if `history` is in the class attributes\n",
    "print(dir(Particle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4dc4c-0325-426f-a85a-ceb5bc0c6c15",
   "metadata": {},
   "source": [
    "Consider the scenario where the target evolves according to the Langevin model, driven by a normal sigma-mean mixture with the mixing distribution being the $\\alpha$-stable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3a32a-bd28-4847-9bc9-46c810cef76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a277e3e-e853-4f90-b431-a5a13b380f48",
   "metadata": {},
   "source": [
    "The state of the target can be represented as 2D Cartesian coordinates, $\\left[x, \\dot x, y, \\dot y\\right]^{\\top}$, modelling both its position and velocity. A simple truth path is created with a sampling rate of 1 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3940b-6e0c-4c2f-bd8a-4844802e0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.groundtruth import GroundTruthPath, GroundTruthState\n",
    "from stonesoup.models.base_driver import GaussianResidualApproxCase\n",
    "from stonesoup.models.driver import AlphaStableNSMDriver \n",
    "from stonesoup.models.transition.levylinear import LevyLangevin, CombinedLinearLevyTransitionModel\n",
    "\n",
    "# And the clock starts\n",
    "start_time = datetime.now().replace(microsecond=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69026f8d-bb9e-4673-b177-45d12cbed859",
   "metadata": {},
   "source": [
    "The `LevyLangevin` class creates a one-dimensional Langevin model, driven by the $\\alpha$-stable NSM mixture process defined in the `AlphaStableNSMDriver` class.\n",
    "\n",
    "\\begin{equation}\n",
    "d \\dot{x}(t)=-\\theta \\dot{x}(t) d t+d W(t), \\quad \\theta>0\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta$ is the damping factor and $W(t)$ is the non-Gaussian driving process.\n",
    "\n",
    "The noise samples $\\mathbf{w}_n$ are drawn from the $\\alpha$-stable distribution parameterized by the $\\alpha$-stable law, $S_{\\alpha}(\\sigma, \\beta, \\mu)$.\n",
    "\n",
    "The input parameters to `AlphaStableNSMDriver` class are the stability index $\\alpha$, expected jumps per unit time $c$, conditional Gaussian mean $\\mu_W$ & variance $\\sigma_W^2$, and the type of residuals used for the truncated shot-noise representation, specified by `noise_case`. \n",
    "\n",
    "Without diving into technical details, the scaling factor $\\sigma$, skewness parameter $\\beta$ and location $\\mu$, in the $\\alpha$-stable law is a function of the conditional Gaussian parameters $\\mu_W, \\sigma_W^2$. In general, set $\\mu_W=0$ for a symmetric target distribution $\\beta=0$, or $\\mu_W \\neq 0$ to model biased trajectories otherwise. In addition, the size of the resulting trajectories (and jumps) can be adjusted by varying $\\sigma_W^2$.\n",
    "\n",
    "The available noise cases are:\n",
    "\n",
    "1. No residuals, `TruncatedCase`, least expensive but drawn noise samples deviate further from target distribution.\n",
    "2. `GaussianResidualApproxCase`, the most expensive but drawn noise samples closest target distribution.\n",
    "3. `PartialGaussianResidualApproxCase`, a compromise between both cases (1) and (2).\n",
    "\n",
    "\n",
    "For interested readers, refer to [1, 2] for more details.\n",
    "\n",
    "Here, we initialise an $\\alpha$-stable driver with the default parameters `mu_W=0, sigma_W2=1, alpha=1.4, noise_case=GaussianResidualApproxCase(), c=10`.\n",
    "\n",
    "Then, the driver instance is injected into the Langevin model for every coordinate axes (i.e., x and y) during initialisation with parameter `damping_coeff=0.15`.\n",
    "\n",
    "Note that we overwrite the default `mu_W` parameter in the $\\alpha$-stable driver for the x-coordinate axes to bias our trajectories towards the left. This can be done by passing an additional argument `mu_W = -0.02` when injecting the driver into the Langevin model.\n",
    "\n",
    "Finallt, the `CombinedLinearLevyTransitionModel` class takes a set of 1-D models and combines them into a linear transition model of arbitrary dimension, $D$, (in this case, $D=2$).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- and  in the $\\alpha$-stable law is a function of the conditional Gaussian mean $\\mu_W$\n",
    "\n",
    "where $\\beta=\\begin{cases} 1, \\quad \\mu_W \\neq 0 \\\\ 0, \\quad \\text{otherwise} \\end{cases}$ with $\\beta=0$ being the a symmetric stable distribution.\n",
    "\n",
    "$\\sigma=\\frac{\\mathbb{E}|w|^\\alpha \\Gamma(2-\\alpha) \\cos(\\pi \\alpha / 2))}{1- \\alpha}$ represent the scale parameter and $\\beta=$ controlling the skewness of the stable distribution. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fd30c-e869-47e6-9cb5-8907df8b1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.models import transition\n",
    "\n",
    "\n",
    "seed = 1 # Random seem for reproducibility\n",
    "\n",
    "# Driving process parameters\n",
    "mu_W = 0\n",
    "sigma_W2 = 4\n",
    "alpha = 1.4\n",
    "c=10\n",
    "noise_case=GaussianResidualApproxCase()\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "theta=0.15\n",
    "\n",
    "driver_x = AlphaStableNSMDriver(mu_W=mu_W, sigma_W2=sigma_W2, seed=seed, c=c, alpha=alpha, noise_case=noise_case)\n",
    "driver_y = driver_x # Same driving process in both dimensions and sharing the same latents (jumps)\n",
    "langevin_x = LevyLangevin(driver=driver_x, damping_coeff=theta, mu_W=-0.02)\n",
    "langevin_y = LevyLangevin(driver=driver_y, damping_coeff=theta)\n",
    "transition_model = CombinedLinearLevyTransitionModel([langevin_x, langevin_y])\n",
    "\n",
    "print(transition_model.model_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2f4db-995e-42df-995c-0b62be09fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transition_model.mu_W)\n",
    "print(transition_model.sigma_W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c85f9-34d1-4d81-bf23-2838f55d0fcf",
   "metadata": {},
   "source": [
    "The ground truth is initialised from (0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381158e-3147-4b6d-a982-4aa959f4c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [start_time]\n",
    "truth = GroundTruthPath([GroundTruthState([0, 1, 0, 1], timestamp=timesteps[0])])\n",
    "\n",
    "num_steps = 40\n",
    "latents_history='begin_latents_history'\n",
    "for k in range(1, num_steps + 1):\n",
    "    timesteps.append(start_time+timedelta(seconds=k))  # add next timestep to list of timesteps\n",
    "    noisy_state,latents_history = transition_model.function(truth[k-1], noise=True, time_interval=timedelta(seconds=1),latents_history=latents_history)\n",
    "    truth.append(GroundTruthState(noisy_state, timestamp=timesteps[k]))\n",
    "print(latents_history) \n",
    "#can't yet think of a way to split the models with same driver that would be generalisable to e.g. different dimensions sampled in each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6d666-f45d-4344-a2d9-865f599e256b",
   "metadata": {},
   "source": [
    "The simulated ground truth path can be plotted using the in-built plotting classes in Stone Soup.\n",
    "\n",
    "In addition to the ground truth, Stone Soup plotting tools allow measurements and predicted tracks (see later) to be plotted and synced together consistently.\n",
    "\n",
    "An animated plotter that uses Plotly graph objects can be accessed via the `AnimatedPlotterly` class from Stone Soup.\n",
    "\n",
    "Note that the animated plotter requires a list of timesteps as an input, and that `tail_length`\n",
    "is set to 0.3. This means that each data point will be on display for 30% of the total\n",
    "simulation time. The mapping argument is [0, 2] because those are the x and\n",
    "y position indices from our state vector.\n",
    "\n",
    "If a static plotter is preferred, the `Plotterly` class can be used instead\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6f18f-8586-4511-9603-248ff7f8a037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from stonesoup.plotter import AnimatedPlotterly\n",
    "# plotter = AnimatedPlotterly(timesteps, tail_length=1.0, width=600, height=600)\n",
    "\n",
    "from stonesoup.plotter import Plotterly\n",
    "plotter = Plotterly(autosize=False, width=600, height=600)\n",
    "plotter.plot_ground_truths(truth, [0, 2])\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1143d2f-aeaa-44e8-8b01-479a80e0601b",
   "metadata": {},
   "source": [
    "## Simulate measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea94e4b-23fc-465d-ad63-d3417eb708a6",
   "metadata": {},
   "source": [
    "Assume a 'linear' sensor which detects the\n",
    "position, but not velocity, of a target, such that\n",
    "$\\mathbf{z}_k = H_k \\mathbf{x}_k + \\boldsymbol{\\nu}_k$,\n",
    "$\\boldsymbol{\\nu}_k \\sim \\mathcal{N}(0,R)$, with\n",
    "\n",
    "\\begin{align}H_k &= \\begin{bmatrix}\n",
    "                    1 & 0 & 0 & 0\\\\\n",
    "                    0  & 0 & 1 & 0\\\\\n",
    "                      \\end{bmatrix}\\\\\n",
    "          R &= \\begin{bmatrix}\n",
    "                  25 & 0\\\\\n",
    "                    0 & 25\\\\\n",
    "               \\end{bmatrix} \\omega\\end{align}\n",
    "\n",
    "where $\\omega$ is set to 25 initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f6231-6728-4ff7-b388-581c4284d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.detection import Detection\n",
    "from stonesoup.models.measurement.linear import LinearGaussian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0ec57-951a-4ba7-b0fb-a0409f21cb1b",
   "metadata": {},
   "source": [
    "The linear Gaussian measurement model is set up by indicating the number of dimensions in the\n",
    "state vector and the dimensions that are measured (so specifying $H_k$) and the noise\n",
    "covariance matrix $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe185d-00bc-4fbc-950c-824ba9bdc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_model = LinearGaussian(\n",
    "    ndim_state=4,  # Number of state dimensions (position and velocity in 2D)\n",
    "    mapping=(0, 2),  # Mapping measurement vector index to state index\n",
    "    noise_covar=np.array([[0.5, 0],  # Covariance matrix for Gaussian PDF\n",
    "                          [0, 0.5]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d2d6b-a6b6-4d9a-8525-764bdfa855cd",
   "metadata": {},
   "source": [
    "The measurements can now be generated and plotted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0346af-dd50-4e2f-b736-1c33baf95326",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = []\n",
    "for state in truth:\n",
    "    measurement = measurement_model.function(state, noise=True)\n",
    "    measurements.append(Detection(measurement,\n",
    "                                  timestamp=state.timestamp,\n",
    "                                  measurement_model=measurement_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6d788-9db9-42ac-8311-59cb037c05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_measurements(measurements, [0, 2])\n",
    "plotter.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b6cae-87a4-4050-a09c-6f511f9b37b8",
   "metadata": {},
   "source": [
    "## Marginalised Particle Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebcae6-4bdf-42fa-8806-443e2b18e576",
   "metadata": {},
   "source": [
    "The `MarginalisedParticlePredictor` and `MarginalisedParticleUpdater` classes correspond to the predict and update steps\n",
    "respectively.\n",
    "Both require a `TransitionModel` and a `MeasurementModel` instance respectively.\n",
    "To avoid degenerate samples, the `SystematicResampler` is used which is passed to the updater.\n",
    "More resamplers that are included in Stone Soup are covered in the\n",
    "[Resampler Tutorial](https://stonesoup.readthedocs.io/en/latest/auto_tutorials/sampling/ResamplingTutorial.html#sphx-glr-auto-tutorials-sampling-resamplingtutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4284e1f-20e5-4d1f-a5da-06cf0c93a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.predictor.particle import MarginalisedParticlePredictor\n",
    "from stonesoup.resampler.particle import SystematicResampler\n",
    "from stonesoup.updater.particle import MarginalisedParticleUpdater\n",
    "\n",
    "predictor = MarginalisedParticlePredictor(transition_model=transition_model)\n",
    "resampler = SystematicResampler()\n",
    "updater = MarginalisedParticleUpdater(measurement_model,resampler=resampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb779115-7823-4bdb-aad1-74d0e076cbdf",
   "metadata": {},
   "source": [
    "To start we create a prior estimate. This is a `MarginalisedParticleState` which describes the state as a distribution of particles.\n",
    "\n",
    "The mean priors are randomly sampled from the standard normal distribution.\n",
    "\n",
    "The covariance priors is initialised with a scalar multiple of the identity matrix ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf7062-e0e3-4ab2-8592-31472ad0d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from stonesoup.types.numeric import Probability  # Similar to a float type\n",
    "from stonesoup.types.state import MarginalisedParticleState\n",
    "from stonesoup.types.array import StateVectors\n",
    "\n",
    "number_particles = 100\n",
    "\n",
    "# Sample from the prior Gaussian distribution\n",
    "states = multivariate_normal.rvs(np.array([0, 1, 0, 1]),\n",
    "                                  np.diag([1., 1., 1., 1.]),\n",
    "                                  size=number_particles)\n",
    "covars = np.stack([np.eye(4) * 100 for i in range(number_particles)], axis=2) # (M, M, N)\n",
    "\n",
    "# Create prior particle state.\n",
    "prior = MarginalisedParticleState(\n",
    "    state_vector=StateVectors(states.T),\n",
    "    covariance=covars,\n",
    "    weight=np.array([Probability(1/number_particles)]*number_particles),\n",
    "                      timestamp=start_time-timedelta(seconds=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fb70b-88a0-4a8d-a0e4-b7911a34be09",
   "metadata": {},
   "source": [
    "## Step 3: Integrate Smoothing into the Filtering Loop\n",
    "After running the forward filtering loop, we can call the backward_smoothing function to obtain smoothed estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac5271-b7b3-44b8-9324-ef1b74d9f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.types.hypothesis import SingleHypothesis\n",
    "from stonesoup.types.particle import Particle\n",
    "from stonesoup.types.track import Track\n",
    "\n",
    "# Check if `history` is in the class attributes\n",
    "# print(dir(Particle))\n",
    "\n",
    "\n",
    "# Perform forward filtering as before\n",
    "track = Track()\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "particle_weights = []\n",
    "particle_means = []\n",
    "particle_covars = []\n",
    "timestamps =[]\n",
    "\n",
    "history= 'begin_history'\n",
    "\n",
    "for measurement in measurements:\n",
    "    timestamps.append(measurement.timestamp)\n",
    "    prediction = predictor.predict(prior, timestamp=measurement.timestamp)\n",
    "\n",
    "    #hypothesis is just a grouping variable, \n",
    "    # which is fed into update funct to generate an update\n",
    "    hypothesis = SingleHypothesis(prediction, measurement)\n",
    "    \n",
    "    post, history=updater.update_with_history(hypothesis,history)\n",
    "    \n",
    "    track.append(post)\n",
    "    prior = track[-1]\n",
    "\n",
    "print(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d028f71",
   "metadata": {},
   "source": [
    "Rao-Blackwellized Particle smoother based on [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e76b6-3183-48c7-b7f9-2a27ae860bfa",
   "metadata": {},
   "source": [
    "## Step 4: Plot the resulting track with the sample points at each iteration. Can also change 'plot_history' to True if wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723a334-818d-4a10-8705-5e0e5a65d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_tracks(track, [0, 2], particle=True, uncertainty=True)\n",
    "plotter.fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonesoup.plotter import AnimatedPlotterly\n",
    "animatedplotter = AnimatedPlotterly(timesteps, tail_length=1.0, width=600, height=600)\n",
    "animatedplotter.plot_ground_truths(truth, [0,2])\n",
    "animatedplotter.plot_measurements(measurements, [0,2])\n",
    "animatedplotter.plot_tracks(track, [0, 2], particle=True, uncertainty=True)\n",
    "animatedplotter.fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c225b-b4fa-481a-9929-89b6168b454c",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Lemke, Tatjana, and Simon J. Godsill, 'Inference for models with asymmetric α -stable noise processes', in Siem Jan Koopman, and Neil Shephard (eds), Unobserved Components and Time Series Econometrics (Oxford, 2015; online edn, Oxford Academic, 21 Jan. 2016)\n",
    "\n",
    "[2] S. Godsill, M. Riabiz, and I. Kontoyiannis, “The L ́evy state space model,” in 2019 53rd Asilomar Conference on Signals, Systems, and Computers, 2019, pp. 487–494.\n",
    "\n",
    "[3] Fredrik Lindsten, Pete Bunch, Simo S¨arkk¨a, Thomas B. Sch¨on, and Simon J. Godsill, \"Rao-Blackwellized particle smoothers for conditionally linear Gaussian models\" in International Conference on Acoustics, Speech, and Signal Processing, 1988. ICASSP-88., 1988 \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stonesoup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
