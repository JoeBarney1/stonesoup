{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-varying mean implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First thing is to introduce a new class which allows a time-varying mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevyDriver(Driver):\n",
    "    \"\"\"Driver type\n",
    "\n",
    "    Base/Abstract class for all conditional Gaussian noise driving processes.\"\"\"\n",
    "\n",
    "    seed: Optional[int] = Property(default=None, doc=\"Seed for random number generation\")\n",
    "    c: np.double = Property(doc=\"Truncation parameter, expected no. jumps per unit time.\")\n",
    "    noise_case: NoiseCase = Property(\n",
    "        default=GaussianResidualApproxCase(),\n",
    "        doc=\"Cases for compensating residuals from series truncation\",\n",
    "    )\n",
    "    mu_W: float = Property(default=0.0, doc=\"Default Gaussian mean\")\n",
    "    sigma_W2: float = Property(default=1.0, doc=\"Default Gaussian variance\")\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.random_state = np.random.default_rng(self.seed)\n",
    "\n",
    "    def rvs(\n",
    "        self,\n",
    "        mean: StateVector,\n",
    "        covar: CovarianceMatrix,\n",
    "        random_state: Generator,\n",
    "        num_samples: int = 1,\n",
    "        **kwargs\n",
    "    ) -> Union[StateVector, StateVectors]:\n",
    "        \"\"\"\n",
    "        returns driving noise term\n",
    "        \"\"\"\n",
    "        if random_state is None:\n",
    "            random_state = self.random_state\n",
    "        noise = random_state.multivariate_normal(\n",
    "            mean.flatten(), covar, size=num_samples\n",
    "        )\n",
    "        noise = noise.T\n",
    "        if num_samples == 1:\n",
    "            return noise.view(StateVector)\n",
    "        else:\n",
    "            return noise.view(StateVectors)\n",
    "\n",
    "    @abstractmethod\n",
    "    def characteristic_func():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _centering(self, e_ft: np.ndarray, truncation: float) -> StateVector:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _hfunc(self, epochs: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"H function\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _thinning_probabilities(self, jsizes: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate thinning probabilities for accept-reject sampling\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _jump_power(self, jszies: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _first_moment(self, truncation: float) -> float:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _second_moment(self, truncation: float) -> float:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _residual_covar(\n",
    "        self, e_ft: np.ndarray, truncation: float, mu_W: float, sigma_W2: float\n",
    "    ) -> CovarianceMatrix:\n",
    "        pass\n",
    "\n",
    "    def _residual_mean(self, e_ft: np.ndarray, truncation: float, mu_W: float) -> CovarianceMatrix:\n",
    "        if isinstance(self.noise_case, TruncatedCase):\n",
    "            m = e_ft.shape[0]\n",
    "            r_mean = np.zeros((m, 1))\n",
    "        elif isinstance(self.noise_case, GaussianResidualApproxCase) or isinstance(\n",
    "            self.noise_case, PartialGaussianResidualApproxCase\n",
    "        ):\n",
    "            r_mean = e_ft * mu_W  # (m, 1)\n",
    "        else:\n",
    "            raise AttributeError(\"invalid noise case\")\n",
    "        return self._first_moment(truncation=truncation) * r_mean  # (m, 1)\n",
    "\n",
    "    def _accept_reject(self, jsizes: np.ndarray, random_state: Generator) -> np.ndarray:\n",
    "        probabilities = self._thinning_probabilities(jsizes)\n",
    "        u = random_state.uniform(low=0.0, high=1.0, size=probabilities.shape)\n",
    "        jsizes = np.where(u <= probabilities, jsizes, 0)\n",
    "        return jsizes\n",
    "\n",
    "    def sample_latents(self, dt: float, num_samples: int, random_state: Optional[Generator] = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if random_state is None:\n",
    "            random_state = self.random_state\n",
    "        # Sample latents pairs\n",
    "        epochs = random_state.exponential(scale=1 / dt, size=(int(self.c * dt), num_samples))\n",
    "        epochs = epochs.cumsum(axis=0)\n",
    "\n",
    "        # Accept reject sampling\n",
    "        jsizes = self._hfunc(epochs=epochs)\n",
    "        jsizes = self._accept_reject(jsizes=jsizes, random_state=random_state)\n",
    "        # Generate jump times\n",
    "        jtimes = random_state.uniform(low=0.0, high=dt, size=jsizes.shape)\n",
    "        return jsizes, jtimes\n",
    "\n",
    "    def mean(\n",
    "        self,\n",
    "        latents: Latents,\n",
    "        ft_func: Callable[..., np.ndarray],\n",
    "        e_ft_func: Callable[..., np.ndarray],\n",
    "        dt: float,\n",
    "        mu_W: Optional[float]=None,\n",
    "        **kwargs\n",
    "    ) -> Union[StateVector, StateVectors]:\n",
    "        \"\"\"Computes a num_samples of mean vectors\"\"\"\n",
    "        mu_W = np.atleast_2d(self.mu_W) if mu_W is None else np.atleast_2d(mu_W)\n",
    "\n",
    "        jtimes = latents.times(driver=self)  # (n_jumps, n_samples)\n",
    "        jsizes = latents.sizes(driver=self)  # (n_jumps, n_samples)\n",
    "        num_samples = latents.num_samples\n",
    "        assert(jsizes.shape[1] == (num_samples) and jtimes.shape[1] == (num_samples))\n",
    "        truncation = self.c * dt\n",
    "        ft = ft_func(dt=dt, jtimes=jtimes)  # (n_jumps, n_samples, m, 1)\n",
    "        series = np.sum(jsizes[..., None, None] * ft, axis=0)  # (n_samples, m, 1)\n",
    "        m = series * mu_W\n",
    "\n",
    "        e_ft = e_ft_func(dt=dt)  # (m, 1)\n",
    "        residual_mean = self._residual_mean(e_ft=e_ft, mu_W=mu_W, truncation=truncation)[None, ...]\n",
    "        centering = dt * self._centering(e_ft=e_ft, mu_W=mu_W, truncation=truncation)[None, ...]\n",
    "        mean = m - centering + residual_mean\n",
    "        if num_samples == 1:\n",
    "            return mean[0].view(StateVector)\n",
    "        else:\n",
    "            return mean.view(StateVectors)\n",
    "\n",
    "    def covar(\n",
    "        self,\n",
    "        latents: Latents,\n",
    "        ft_func: Callable[..., np.ndarray],\n",
    "        e_ft_func: Callable[..., np.ndarray],\n",
    "        dt: float,\n",
    "        mu_W: Optional[float] = None,\n",
    "        sigma_W2: Optional[float] = None,\n",
    "        **kwargs\n",
    "    ) -> Union[CovarianceMatrix, CovarianceMatrices]:\n",
    "        \"\"\"Computes covariance matrix / matrices\"\"\"\n",
    "        mu_W = np.atleast_2d(self.mu_W) if mu_W is None else np.atleast_2d(mu_W)\n",
    "        sigma_W2 = np.atleast_2d(self.sigma_W2) if sigma_W2 is None else np.atleast_2d(sigma_W2)     \n",
    "\n",
    "        jsizes = self._jump_power(latents.sizes(driver=self))  # (n_jumps, n_samples)\n",
    "        jtimes = latents.times(driver=self)\n",
    "        num_samples = latents.num_samples\n",
    "        assert(jsizes.shape[1] == (num_samples) and jtimes.shape[1] == (num_samples))\n",
    "\n",
    "        truncation = self._hfunc(self.c * dt)\n",
    "\n",
    "        ft = ft_func(dt=dt, jtimes=jtimes)  # (n_jumps, n_samples, m, 1)\n",
    "        ft2 = np.einsum(\"ijkl, ijml -> ijkm\", ft, ft)  # (n_jumps, n_samples, m, m)\n",
    "        series = np.sum(jsizes[..., None, None] * ft2, axis=0)  # (n_samples, m, m)\n",
    "        s = sigma_W2 * series\n",
    "\n",
    "        e_ft = e_ft_func(dt=dt)  # (m, 1)\n",
    "        residual_cov = self._residual_covar(e_ft=e_ft, mu_W=mu_W, sigma_W2=sigma_W2, truncation=truncation)\n",
    "        covar = s + residual_cov\n",
    "        if num_samples == 1:\n",
    "            return covar[0].view(CovarianceMatrix)  # (m, m)\n",
    "        else:\n",
    "            return covar.view(CovarianceMatrices)  # (n_samples, m, m)\n",
    "\n",
    "\n",
    "class NormalSigmaMeanDriver(LevyDriver):\n",
    "    def _jump_power(self, jsizes: np.ndarray) -> np.ndarray:\n",
    "        return jsizes**2\n",
    "\n",
    "    def _residual_covar(\n",
    "        self, e_ft: np.ndarray, truncation: float, mu_W: float, sigma_W2: float, **kwargs\n",
    "    ) -> CovarianceMatrix:\n",
    "        mu_W = mu_W\n",
    "        sigma_W2 = sigma_W2\n",
    "        if isinstance(self.noise_case, TruncatedCase):\n",
    "            m = e_ft.shape[0]\n",
    "            r_cov = np.zeros((m, m))\n",
    "        elif isinstance(self.noise_case, GaussianResidualApproxCase):\n",
    "            r_cov = (\n",
    "                e_ft @ e_ft.T * self._second_moment(truncation=truncation) * (mu_W**2 + sigma_W2)\n",
    "            )\n",
    "        elif isinstance(self.noise_case, PartialGaussianResidualApproxCase):\n",
    "            r_cov = e_ft @ e_ft.T * self._second_moment(truncation=truncation) * sigma_W2\n",
    "        else:\n",
    "            raise AttributeError(\"Invalid noise case.\")\n",
    "        return r_cov  # (m, m)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
